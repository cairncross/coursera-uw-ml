{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "train = pd.read_csv('kc_house_train_data.csv',dtype=dtype_dict)\n",
    "test = pd.read_csv('kc_house_test_data.csv',dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    feature_matrix = data[features].as_matrix(columns=None)\n",
    "\n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    # features_matrix = features\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = data[output].as_matrix(columns=None) # GraphLab Create>= 1.7!!\n",
    "    return (feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis=0)\n",
    "    normalized_features = features / norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.6,  0.6,  0.6],\n",
       "        [ 0.8,  0.8,  0.8]]), array([  5.,  10.,  15.]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_features(np.array([[3,6,9],[4,8,12]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['sqft_living', 'bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(feature_matrix, output_array) = get_numpy_data(sales, features, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00680209,  0.00353021,  0.00583571],\n",
       "        [ 0.00680209,  0.00768869,  0.00583571],\n",
       "        [ 0.00680209,  0.00230361,  0.00389048],\n",
       "        ..., \n",
       "        [ 0.00680209,  0.00305154,  0.00389048],\n",
       "        [ 0.00680209,  0.00478673,  0.00583571],\n",
       "        [ 0.00680209,  0.00305154,  0.00389048]]),\n",
       " array([  1.47013605e+02,   3.34257264e+05,   5.14075870e+02]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(normalized_features, norms) = normalize_features(feature_matrix)\n",
    "normalized_features, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.array([1, 4, 1])\n",
    "predictions = predict_output(normalized_features, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ro_1 = np.dot(normalized_features[:,1],(output_array - predictions + weights[1]*normalized_features[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ro_2 = np.dot(normalized_features[:,2],(output_array - predictions + weights[2]*normalized_features[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87939470.8233 80966698.6662\n"
     ]
    }
   ],
   "source": [
    "print ro_1, ro_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix, weights)\n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    ro_i = np.dot(feature_matrix[:,i],(output - prediction + weights[i]*feature_matrix[:,i]))\n",
    "    \n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = ro_i\n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i+ l1_penalty/2\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i- l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425558846691\n"
     ]
    }
   ],
   "source": [
    "# should print 0.425558846691\n",
    "import math\n",
    "print lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],\n",
    "                   [2./math.sqrt(13),3./math.sqrt(10)]]), np.array([1., 1.]), np.array([1., 4.]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    weights = initial_weights\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        max_change = 0\n",
    "        for i in range(len(weights)):\n",
    "            old_weight_i = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            change = np.abs(weights[i] - old_weight_i)\n",
    "            if change > max_change:\n",
    "                max_change = change\n",
    "        if max_change < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following parameters, learn the weights on the sales dataset.\n",
    "\n",
    "* Initial weights = all zeros\n",
    "* L1 penalty = 1e7\n",
    "* Tolerance = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21624997.95951911,  63157247.20788954,         0.        ])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cyclical_coordinate_descent(normalized_features, output_array, np.array([0., 0., 0.]), 1e7, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_weights = np.array([ 21624997.95951911,  63157247.20788954,         0.        ])\n",
    "predictions = predict_output(normalized_features, lasso_weights)\n",
    "RSS = np.sum((output_array - predictions) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63049247672e+15\n"
     ]
    }
   ],
   "source": [
    "print RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating LASSO fit with more features\n",
    "17. Let us split the sales dataset into training and test sets. If you are using GraphLab Create, call ‘random_split’ with .8 ratio and seed=0. Otherwise, please down the corresponding csv files from the downloads section.\n",
    "\n",
    "18. Create a normalized feature matrix from the TRAINING data with the following set of features.\n",
    "\n",
    "bedrooms, bathrooms, sqft_living, sqft_lot, floors, waterfront, view, condition, grade, sqft_above, sqft_basement, yr_built, yr_renovated\n",
    "\n",
    "Make sure you store the norms for the normalization, since we’ll use them later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = 'price'\n",
    "(train_feature_matrix, train_output_array) = get_numpy_data(train, train_features, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(normalized_train, norms_train) = normalize_features(train_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. First, learn the weights with l1_penalty=1e7, on the training data. Initialize weights to all zeros, and set the tolerance=1. Call resulting weights’ weights1e7’, you will need them later.\n",
    "\n",
    "20. Quiz Question: What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_train, train_output_array, initial_weights, 1e7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        2.442960e+07\n",
       "bedrooms         0.000000e+00\n",
       "bathrooms        0.000000e+00\n",
       "sqft_living      4.838917e+07\n",
       "sqft_lot         0.000000e+00\n",
       "floors           0.000000e+00\n",
       "waterfront       3.317511e+06\n",
       "view             7.329962e+06\n",
       "condition        0.000000e+00\n",
       "grade            0.000000e+00\n",
       "sqft_above       0.000000e+00\n",
       "sqft_basement    0.000000e+00\n",
       "yr_built         0.000000e+00\n",
       "yr_renovated     0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e7,index=['intercept']+ train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Next, learn the weights with l1_penalty=1e8, on the training data. Initialize weights to all zeros, and set the tolerance=1. Call resulting weights ‘weights1e8’, you will need them later.\n",
    "\n",
    "22. Quiz Question: What features had non-zero weight in this case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_train, train_output_array, initial_weights, 1e8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        7.111463e+07\n",
       "bedrooms         0.000000e+00\n",
       "bathrooms        0.000000e+00\n",
       "sqft_living      0.000000e+00\n",
       "sqft_lot         0.000000e+00\n",
       "floors           0.000000e+00\n",
       "waterfront       0.000000e+00\n",
       "view             0.000000e+00\n",
       "condition        0.000000e+00\n",
       "grade            0.000000e+00\n",
       "sqft_above       0.000000e+00\n",
       "sqft_basement    0.000000e+00\n",
       "yr_built         0.000000e+00\n",
       "yr_renovated     0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e8,index=['intercept']+ train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Finally, learn the weights with l1_penalty=1e4, on the training data. Initialize weights to all zeros, and set the tolerance=5e5. Call resulting weights ‘weights1e4’, you will need them later. (This case will take quite a bit longer to converge than the others above.)\n",
    "\n",
    "24. Quiz Question: What features had non-zero weight in this case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_train, train_output_array, initial_weights, 1e4, 5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        7.856474e+07\n",
       "bedrooms        -2.209740e+07\n",
       "bathrooms        1.279107e+07\n",
       "sqft_living      9.380809e+07\n",
       "sqft_lot        -2.013173e+06\n",
       "floors          -4.219185e+06\n",
       "waterfront       6.482843e+06\n",
       "view             7.127409e+06\n",
       "condition        5.001665e+06\n",
       "grade            1.432752e+07\n",
       "sqft_above      -1.577096e+07\n",
       "sqft_basement   -5.159591e+06\n",
       "yr_built        -8.449534e+07\n",
       "yr_renovated     2.824439e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e4,index=['intercept']+ train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling learned weights\n",
    "25. Recall that we normalized our feature matrix, before learning the weights. To use these weights on a test set, we must normalize the test data in the same way. Alternatively, we can rescale the learned weights to include the normalization, so we never have to worry about normalizing the test data:\n",
    "\n",
    "In this case, we must scale the resulting weights so that we can make predictions with original features:\n",
    "\n",
    "Store the norms of the original features to a vector called ‘norms’:\n",
    "\n",
    "features, norms = normalize_features(features)\n",
    "\n",
    "Run Lasso on the normalized features and obtain a ‘weights’ vector\n",
    "Compute the weights for the original features by performing element-wise division, i.e.\n",
    "\n",
    "weights_normalized = weights / norms\n",
    "\n",
    "Now, we can apply weights_normalized to the test data, without normalizing it!\n",
    "\n",
    "26. Create a normalized version of each of the weights learned above. (‘weights1e4’, ‘weights1e7’, ‘weights1e8’). To check your results, if you call ‘normalized_weights1e7’ the normalized version of ‘weights1e7’, then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_weights1e4 = weights1e4 / norms_train\n",
    "normalized_weights1e7 = weights1e7 / norms_train\n",
    "normalized_weights1e8 = weights1e8 / norms_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.317457646\n"
     ]
    }
   ],
   "source": [
    "print normalized_weights1e7[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating each of the learned models on the test data\n",
    "27. Let's now evaluate the three models on the test data. Extract the feature matrix and output array from the TEST set. But this time, do NOT normalize the feature matrix. Instead, use the normalized version of weights to make predictions.\n",
    "\n",
    "Computemthe RSS of each of the three normalized weights on the (unnormalized) feature matrix.\n",
    "\n",
    "28. Quiz Question: Which model performed best on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output_array) = get_numpy_data(test, train_features, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions1e4 = predict_output(test_feature_matrix, weights1e4)\n",
    "predictions1e7 = predict_output(test_feature_matrix, weights1e7)\n",
    "predictions1e8 = predict_output(test_feature_matrix, weights1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RSS1e4 = np.sum((test_output_array - predictions1e4) ** 2)\n",
    "RSS1e7 = np.sum((test_output_array - predictions1e7) ** 2)\n",
    "RSS1e8 = np.sum((test_output_array - predictions1e8) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.55258078738e+25 5.09512950079e+25 2.10624234224e+19\n"
     ]
    }
   ],
   "source": [
    "print RSS1e4, RSS1e7, RSS1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
